name: Data Backfill

# Manual workflow for initial data backfill or catch-up
on:
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset to backfill'
        required: true
        default: 'prices'
        type: choice
        options:
          - prices
          - fundamentals
          - features
          - valuation_stats
          - technical
          - valuation

      tickers:
        description: 'Tickers to backfill (comma-separated, leave empty for all active)'
        required: false
        default: ''

      start_date:
        description: 'Start date (YYYY-MM-DD)'
        required: false
        default: ''

      end_date:
        description: 'End date (YYYY-MM-DD, defaults to today)'
        required: false
        default: ''

jobs:
  backfill:
    name: Backfill ${{ github.event.inputs.dataset }}
    runs-on: ubuntu-latest
    timeout-minutes: 240  # 4 hours for large backfills
    environment: prod-actions

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Install dependencies
        run: uv sync

      - name: Run backfill (raw data)
        if: ${{ github.event.inputs.dataset == 'prices' || github.event.inputs.dataset == 'fundamentals' }}
        env:
          ENV: REMOTE
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
          EODHD_API_KEY: ${{ secrets.EODHD_API_KEY }}
        run: |
          echo "Backfilling ${{ github.event.inputs.dataset }} from Dolt..."
          uv run python scripts/backfill_from_dolt.py \
            --dataset ${{ github.event.inputs.dataset }} \
            ${{ github.event.inputs.tickers && format('--tickers {0}', github.event.inputs.tickers) || '--ticker-file tickers.txt' }} \
            ${{ github.event.inputs.start_date && format('--start-date {0}', github.event.inputs.start_date) || '' }} \
            ${{ github.event.inputs.end_date && format('--end-date {0}', github.event.inputs.end_date) || '' }}

      # ===================================================================
      # Backfill Features (new wide table with point-in-time fundamentals)
      # ===================================================================
      - name: Backfill features
        if: ${{ github.event.inputs.dataset == 'features' }}
        env:
          ENV: REMOTE
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          echo "======================================================================"
          echo "BACKFILL FEATURES (with point-in-time fundamentals)"
          echo "======================================================================"

          # Build args
          ARGS="--backfill"

          # Start date is required for backfill
          if [ -z "${{ github.event.inputs.start_date }}" ]; then
            echo "Error: start_date is required for features backfill"
            exit 1
          fi
          ARGS="$ARGS --start-date ${{ github.event.inputs.start_date }}"

          if [ -n "${{ github.event.inputs.end_date }}" ]; then
            ARGS="$ARGS --end-date ${{ github.event.inputs.end_date }}"
          fi

          if [ -n "${{ github.event.inputs.tickers }}" ]; then
            # Convert comma-separated to space-separated
            TICKERS=$(echo "${{ github.event.inputs.tickers }}" | tr ',' ' ')
            ARGS="$ARGS --tickers $TICKERS"
          fi

          echo "Running: python -m src.features.features_compute $ARGS"
          uv run python -m src.features.features_compute $ARGS

      # ===================================================================
      # Backfill Valuation Stats (for historical percentile templates)
      # ===================================================================
      - name: Backfill valuation stats
        if: ${{ github.event.inputs.dataset == 'valuation_stats' }}
        env:
          ENV: REMOTE
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          echo "======================================================================"
          echo "BACKFILL VALUATION STATS"
          echo "======================================================================"

          # Build args - use --backfill to read from signals_valuation
          ARGS="--backfill"

          if [ -n "${{ github.event.inputs.tickers }}" ]; then
            # Convert comma-separated to space-separated
            TICKERS=$(echo "${{ github.event.inputs.tickers }}" | tr ',' ' ')
            ARGS="$ARGS --tickers $TICKERS"
          fi

          echo "Running: python -m src.features.pipeline_weekly_stats $ARGS"
          uv run python -m src.features.pipeline_weekly_stats $ARGS

      # ===================================================================
      # Compute signals (technical/valuation) - legacy datasets
      # ===================================================================
      - name: Compute signals (technical/valuation)
        if: ${{ github.event.inputs.dataset == 'technical' || github.event.inputs.dataset == 'valuation' }}
        env:
          ENV: REMOTE
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          echo "Computing ${{ github.event.inputs.dataset }} signals (legacy)..."

          # Determine flag based on dataset
          if [ "${{ github.event.inputs.dataset }}" = "technical" ]; then
            SIGNAL_FLAG="--technical-only"
          else
            SIGNAL_FLAG="--valuation-only"
          fi

          # Get tickers list
          if [ -n "${{ github.event.inputs.tickers }}" ]; then
            TICKERS="${{ github.event.inputs.tickers }}"
          else
            TICKERS=$(cat tickers.txt | tr '\n' ' ')
          fi

          # Compute for each ticker with --force to recompute all dates
          for ticker in $TICKERS; do
            echo "Computing signals for $ticker..."
            uv run python scripts/compute_metrics.py \
              --ticker $ticker \
              $SIGNAL_FLAG \
              --force \
              ${{ github.event.inputs.start_date && format('--start-date {0}', github.event.inputs.start_date) || '' }} \
              ${{ github.event.inputs.end_date && format('--end-date {0}', github.event.inputs.end_date) || '' }} \
              || echo "Warning: Failed to compute signals for $ticker"
          done

      - name: Upload backfill logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backfill-logs-${{ github.event.inputs.dataset }}-${{ github.run_number }}
          path: |
            logs/*.log
            *.log
          retention-days: 30

      - name: Verify backfill results
        if: success()
        env:
          ENV: REMOTE
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          echo "Verifying backfill results..."
          uv run python -c "
          from src.reader import TimeSeriesReader
          r = TimeSeriesReader()
          tickers = r.list_available_tickers('${{ github.event.inputs.dataset }}')
          print(f'âœ… Dataset ${{ github.event.inputs.dataset }} contains {len(tickers)} tickers')
          "
